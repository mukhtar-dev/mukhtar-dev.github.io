---
layout: default
title: Mukhtar | Data Engineer
---


# 👋 Hi, I'm Mukhtar

I am a **Data Engineer** with experience in:
- SQL, Oracle
- Python, PySpark
- ETL pipelines
- Hive, Snowflake
- SAP data & CDC (Change Data Capture)

I build robust, scalable data pipelines and warehouse solutions that support real-time analytics and decision-making.

---

## 🎓 Certifications & Training

### Big Data Master Program (7 months)
Hands-on training in:
- Apache Spark (in depth)
- Azure: Databricks, Data Factory, Synapse
- AWS: S3, Redshift, Glue,EMR, Athena

### Databricks Data Engineer Certified Associate

### Snowflake for Data Engineers *(Udemy Course)*
Practical course focused on Snowflake architecture, SQL-based transformations, and dbt integration.

---

## 📂 Projects

### 1. Project: Change Data Capture with Apache Hudi, Debezium, Kafka & Spark
How to captures real-time changes from a PostgreSQL database, streams them via Kafka, writes to a Hudi data lake, and incrementally updates an aggregated table
[🔗 View on GitHub](https://github.com/mukhtar-dev/cdc-apache-hudi)

### 2. Project: Xetra ETFs ETL Pipeline using Python, Pandas and AWS S3
An ETL pipeline for processing and analyzing Exchange Traded Funds (ETFs) data using Python from the Xetra trading platform stored on S3
[🔗 View on GitHub](https://github.com/mukhtar-dev/xetra_etl)

### 3. Project: dbt + Snowflake Pipeline
A dbt project connecting to Snowflake with staging, transformation, and documentation layers.
[🔗 View on GitHub](https://github.com/mukhtar-dev/dbtlearn)



---

## 🛠️ Technical Skills
- **Languages**: SQL, Python
- **Tools**: dbt, Airflow, Jupyter, Git
- **Big Data**: PySpark, Hive
- **Cloud/Warehousing**: Snowflake, Oracle
- **Others**: SAP data, CDC, ETL workflows

---

## 📄 CV
[Download My CV](Mukhtar_CV.pdf)


---

## 🔗 Connect
- [LinkedIn](https://linkedin.com/in/mukhtar-isam-mukhtar-8932b791)
- [GitHub](https://github.com/mukhtar-dev)
